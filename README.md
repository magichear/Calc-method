`2025`春季学期`twh`班计算方法A代码实现

我会尽量使用面向对象的思想编辑代码，并加入一些有趣的东西

[TOC]

### Lab 1

>分别计算级数函数 $\phi = \sum ^{\infty} _{k=1} \dfrac{1}{k(k+x)}$在`x`值为0.0, 0.5, 1.0, $\sqrt{2}$, 10.0, 100.0, 300.0时的值，要求误差小于$10^{-6}$

首先使用了暴力算法，穷举指定位数直到基本合格为止

$$1\_000\_000 \ge k \ge  \dfrac{x}{e^{x * 10^{-6}} - 1}$$

不过我这里观察这个最大值达不到要求，再加两个数量级勉强可以，但是这样算会很慢

- 思路一：引入多线程
    - 这里用了`Lambda`
        - 直接在函数内定义，更方便，还能直接用上面定义的变量（可以少传参）
    - 由于我们需要顺序输出，而多线程的返回时间是不确定的，因此要引入锁
        - 同时由于要求顺序，所以这里需要引入`condition_variable`
        - 并且只能使用`unique_lock`
        - 这样可以保证所有线程同时计算，并且按顺序返回
            - 传参中有索引，每个线程结束前会把索引自增，将锁移交给下一个线程
- 思路二：开（去）动（查）脑（资）筋（料）
    - 首先，级数本身可以化简为$ S(x) = \dfrac{1}{x} [ψ(x+1) + γ]$
        - γ 为欧拉-马歇罗尼常数，ψ(x) 为 digamma 函数
        - γ ≈ 0.57721566490153286060651209
    - x=0
        - 巴塞尔问题
        - $result =  \dfrac{\pi ^2 }{ 6}$     
    - x=0.5
        - $ψ(0.5 + 1) = -γ - 2ln2 + 2$
        - $result =  4(1-ln2)$
    - x=1   
        - 望远镜，展开中间就消掉了（直接返回1理论上应该也可以，不过还是做做样子算一下吧）
        - result =  1 - 1/(k+1)
    -  x=$\sqrt{2}$  
        - result = xxxxxx                 
        - 由于要求不准调库，这里只能剥蒜
            - 不然`cmath`里就有
            - `java`里的库在`apache`，`py`也有
    -  x= n  
        - result =  $\dfrac{H_n}{n}$         
        - 调和级数 $H_n = 1 + 1/2 + 1/3 + ... + 1/n$，n为正整数
        - 这里可以修改为$$\dfrac{((2+1)*3 + 2*1) + ...}{1*2*3*...*n}$$
            - 首先，整数乘法不会丢精度（只要不溢出），这样我们只会有一步除法需要考虑精度丢失的问题
    - 整体性能瓶颈在于$\sqrt{2}$的爆算，不过问题不是很大，并且我们还有多线程
        - 这就体现出接口设计的重要性了
```
阿祖，都看到这里了，背一下吧：封装、继承、多态
顺便可以看看线程/进程间通信、两者区别（共享堆栈、条件变量、线程安全的队列；管道、消息队列、共享内存、套接字；前者共享资源，开销小速度快|后者开销大但更安全。适用场景不同），
以及线程池的关键参数及其意义（核心/最大线程数、任务队列、存活时间、拒绝策略、线程工厂, etc）
还有两种锁的区别和 emplace_back 跟 push_back 在构造上的区别
```

另外，老师第一周讲了误差分析，给了几个公式，但是似乎没讲误差传播公式（也可能是我没听（

如果 $ z $ 是 $ x $ 和 $ y $ 的函数，那么 $ z $ 的误差可以通过对 $ x $ 和 $ y $ 的偏导数来近似计算： $ e(z) \approx \left| \frac{\partial z}{\partial x} \right| e(x) + \left| \frac{\partial z}{\partial y} \right| e(y) $

有了这个公式再算是不是就很简单了：$ e\left( \frac{x}{y} \right) \approx \left| \frac{1}{y} \right| e(x) + \left| -\frac{x}{y^2} \right| e(y) $

相应的，相对误差也可以代公式（x+y看成一个整体）
$$
\begin{aligned}
e_r(x + y) \approx& \dfrac{e(x+y)}{x+y} \approx \dfrac{1·x · e(x)/x + 1·y · e(y)/y}{x+y}\\
\approx&\frac{x e_r(x) + y e_r(y)}{|x + y|}  记住这个绝对值
\end{aligned}
$$
对于乘法和除法（自己算哦）： 
$$ 
e_r(x \cdot y) \approx e_r(x) + e_r(y) $$
$$ e_r\left(\frac{x}{y}\right) \approx e_r(x) - e_r(y) 
$$

### Lab2

这一次的原理比较简单，而且没有明确要求精度。

`n`阶拉格朗日插值，分别计算定长节点、切比雪夫节点与原函数在多个测试点处的近似最大模误差

允许自定义并传入插值节点生成方法指针与原始函数指针

在计算基函数时，分母自然是每项都算一遍；对于分子，如果每一项都重新全部乘一遍就太浪费了，可以先正反各遍历一遍求出前缀积与后缀积，这样在计算某项时只需要将**前缀积与后缀积**的对应位置乘起来就是这一项的分子，分母从预先计算好的向量里取出对应位置


`n`阶插值需要`n+1`个节点

```sh
Equidist
Node count = 6, Max mod Error = 4.326923076923077e-01
Node count = 11, Max mod Error = 1.915643050219250e+00
Node count = 21, Max mod Error = 5.976568477453189e+01
Node count = 41, Max mod Error = 1.039408117698964e+05

Chebyshev
Node count = 6, Max mod Error = 5.559113388123955e-01
Node count = 11, Max mod Error = 1.091467246497665e-01
Node count = 21, Max mod Error = 1.532508854382740e-02
Node count = 41, Max mod Error = 2.889123107673062e-04
```